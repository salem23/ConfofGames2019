%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Thin Formal Letter
% LaTeX Template
% Version 2.0 (7/2/17)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Author:
% Vel (vel@LaTeXTemplates.com)
%
% Originally based on an example on WikiBooks 
% (http://en.wikibooks.org/wiki/LaTeX/Letters) but rewritten as of v2.0
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[10pt]{letter} % 10pt font size default, 11pt and 12pt are also possible
\usepackage{geometry} % Required for adjusting page dimensions
\usepackage{lmodern}
\usepackage{hyperref}
%\longindentation=0pt % Un-commenting this line will push the closing "Sincerely," to the left of the page

\geometry{
	paper=a4paper, % Change to letterpaper for US letter
	top=3cm, % Top margin
	bottom=1.5cm, % Bottom margin
	left=4.5cm, % Left margin
	right=4.5cm, % Right margin
	%showframe, % Uncomment to show how the type block is set on the page
}

\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage[utf8]{inputenc} % Required for inputting international characters

\usepackage{stix} % Use the Stix font by default

\usepackage{microtype} % Improve justification
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,
	urlcolor=cyan,
}


\signature{Mohammed SALEM} % Your name for the signature at the bottom

\address{SALEM Mohammed \\ University of Mascara \\ Algeria\\ salem@univ-mascara.dz}

%---------------------------------------------------------------------------------

\begin{document}

%----------------------------------------------------------------------------------------
%	ADDRESSEE SECTION
%----------------------------------------------------------------------------------------

\begin{letter}{Professor Julian Togelius \\ Editor in Chief, IEEE Transactions on Games} % Name/title of the addressee

%----------------------------------------------------------------------------------------
%	LETTER CONTENT SECTION
%----------------------------------------------------------------------------------------
\opening{Subject: Revision and resubmission of manuscript TCIAIG-2019-0090.R2\\
	\\	
\textbf{Dear Dr Togelius,}}

Thank you for your consideration of our manuscript entitled "Overtaking Uncertainty with Evolutionary TORCS controllers: Combining BLX with Decreasing $\alpha$ Operator and Grand Prix Selection". 
We would also like to take this opportunity to thank the reviewers for
their positive feedback and their requests for correction or modification. Thus, we have checked and addressed the reviewers' comments that we found very helpful, and believe our revised manuscript - which you will find uploaded alongside this document -, represents a significant improvement over our previous submission. \\


We have appended the reviewers' comments below in this letter and answered to them point by point, indicating exactly how we have addressed each concern or request, and describing the changes we have made in the manuscript.\\
The revisions have been approved by all the authors and I personally have again been chosen as the corresponding author.
We sincerely hope the revised manuscript worth being accepted for publication in the Journal.

Thank you for your time and consideration.

We look forward to hear your reply.

\vspace{2\parskip} % Extra whitespace for aesthetics
\closing{Sincerely yours,}
\vspace{2\parskip} % Extra whitespace for aesthetics

\ps{P.S. You can find additional information attached to this letter.} % Postscript text, comment this line to remove it

\newpage

	% #############################################################################

{\bf \underline{ Responses to Editor's  Comments to the authors}}\\
\begin{itemize}
 \item 	\bf  {\bf AE's Comments to Author:}
		\begin{quote}
Thank you for the previous revisions of this manuscript. The paper has improved significantly after addressing the different comments from the reviewers. The two reviews below highlight minor modifications that nevertheless should be addressed. Note that I do not recommend doing extra experiments for this manuscript, just provide the explanations/justifications and corrections asked by the reviewers.
		\end{quote}
 \item {\bf Response:} 
We thank the editor. We responded to the comments of the reviewers and
highlights changes in the text.

\end{itemize}
\newpage
{\bf
\underline{
 Reviewers Comments, Author Responses and Manuscript Changes}}
\begin{enumerate}
% #############################################################################

\item {\bf \underline{ Reviewer 1 Comments}}\\
		Comments to the Author:\\
	I would like to thank the authors for the made changes. Added explanations on robustness, uncertainty and fitness-less as well as corrected typos and grammar errors make the paper much more readable.
	
	I didn't have much to comment on the previous version, but I am glad that the other reviewers had so many comments which have been addressed in this version. My remaining remarks all consider the presentation and are listed below:
\begin{itemize}
	\item {\bf Comment 1:}
	\begin{quote}	
	- Figure 4: the figure is still stretched in the x axis. Comparing it to the figure provided via the link in the authors comments, show that the original image has not been stretched.\\
	- Figure 5: labels are not readable and the image is very stretched in the x-axis\\
% Antonio - It is still hard to be read
	- Table 3: the right border in the second row is missing\\
	- Table 4: the right border is missing in the header of the table
	\end{quote}	
	\item {\bf Response:} 
		We thank the reviewer for these helpful remarks. Figure 4 and Figure.5 have been redrawn and the problem of missing lines of Tables 3 and 4 is fixed.
\end{itemize}

We are very grateful to this reviewer for his/her useful and kind comments.

\newpage

% ##############################################################################

\item {\bf \underline{ Reviewer 2 Comments}}\\
	Comments to the Author\\
This paper proposes a new evaluation function and a recombination operator for evolving TORCS controllers. However, several aspects need to be considered and a thorough revision of the paper's language.

	\begin{itemize}

		\item {\bf Comment 1:}
		\begin{quote}
	It is questionable to use the term "fitness-less." Isn't the sum of ranks in several races can be seen as an individual's fitness? I think the word "relative-fitness" is more suitable.
		\end{quote}
		\item {\bf Response:} Except when referring to actual
                  papers or methods that were denominated in that
                  fashion, we have eliminated this term referring to
                  our own work. What the reviewer suggested,
                  ``relative fitness'' would be a good substitute, but
                  since it's actually arrived at via competiton, we
                  have used {\em competitive-based fitness} or other
                  similar terms that refer to this fact, instead of
                  using fitnessless. We thank the reviewer for this
                  suggestion.

\item {\bf Comment 2}	
		\begin{quote}
	The authors argue that by learning in a competitive environment instead of a solo environment, the layer of uncertainty can be eliminated. However, to verify the claim, the following aspects are needed to be addressed.
		\end{quote}	
	\begin{itemize}	
%%			\begin{enumerate}	
		\item {\bf Comment 2.1:}				
		\begin{quote}
When learning in a competitive environment, several additional variables are expected to be involved, e.g., the track to be used, the number of competing vehicles, the type of competing vehicles, and the competing vehicles' recklessness, etc. How do these variables affect the learning performance? Additional experiments in this regard appear to be necessary. Learning in a competitive environment does really eliminate the uncertainty?
			\end{quote}	
			\item {\bf Response:}
			Uncertainty can't simply be eliminated;
                        however, you can mitigate it by making what
                        you use to evolve as close as possible to the
                        actual problem that you want solved:
                        maximizing the probability of winning a
                        race. So, by changing a surrogate model (that
                        uses fitness in a solo race as a surrogate of
                        success in competitive races) by actual
                        competitive races in well chosen tracks and
                        competing with the rest of co-evolving
                        individuals, we manage to make what drives
                        evolution closer to the actual problem, and
                        thus the evolved solution less uncertain in
                        its possible success. This has been clarified
                        in the text. The rest of the mentioned
                        variables are actually taken into account by
                        careful and heuristic choice of values; the
                        competitors are actually the rest of the
                        individuals in the population, so it's a kind
                        of coevolution. By comparing it with other,
                        non-evolved members, you might get some
                        additional information on the fitness, and
                        that is indeed a good suggestion for future
                        work, for which we are really grateful. For
                        the time being, that introduction of another
                        variable in the problem was not considered for
                        this paper.
		\item {\bf Comment 2.2:}
		\begin{quote}
When learning in a competitive environment, does the learned controller work well in a solo environment? Additional experiments in this regard appear to be necessary.
			\end{quote}	
		\item {\bf Response:} 
		We thank the reviewer for the comment, We agree that additional experiments would be needed to test the learned controller in solo environment, but the aim of our paper is to design a controller for TORCS races trying to reduce uncertainty and we argue that competitive environment are more uncertain and difficult to train a good bot.
		
	%%	Mohammed
		\item {\bf Comment 2.3:}
		\begin{quote}
Why have several existing studies mainly suggested learning in a solo environment? And, have there been any studies conducted in a competitive environment in the past?
			\end{quote}	
		\item {\bf Response:} 

	As it is explained in the text (page 2), solo races are more
        convenient for the `training' stage (i.e. the evolutionary
        process), since the incorporation of rivals includes an
        additional uncertainty source to the fitness due to their `unexpected'
        behaviour during the races. Using competition to evaluate
        controllers is also much slower; you need several races with
        different combinations of cars, while you need a single one,
        by definition, in a ``solo'' race.
        Thus, considering the car is being optimised by itself allows to improve its general behavioural patterns (in a surrogate model). Moreover, it must be remarked that TORCS sensors simply detect `obstacles' or `objects' around the car, which can be the track limits or other cars, so, in both cases, our car must avoid impacting with them.

With regard to other works, most of them follow a similar approach, i.e. they design and optimise their controllers in solo races, even in works like the one by Cardamone et al., in which an on-line (during the game) procedure is considered, but with no opponents to deal with.

The reference is:\\
L. Cardamone, D. Loiacono, and P. L. Lanzi, ``On-line neuroevolution
applied to the open racing car simulator,'' in Proceedings of the Eleventh
Conference on Congress on Evolutionary Computation, ser. CEC`09.
Piscataway, NJ, USA: IEEE Press, 2009, pp. 2622-2629.\\
		
There are some studies like the one by D.P. Li\'ebana et al. that consider rivals during the optimisation procedure, but due to that fact, they cannot extract firm conclusions regarding their proposed approach.
Also, Loiacono et al. published a proposal of an algorithm to learn overtaking manoeuvre, which obviously considers opponents during the training stage, but since they are part of the problem to solve.

The references are:\\
D.P. Li\'ebana, G. Recio, Y. S\'aez, and P. Isasi, ``Evolving a fuzzy
controller for a car racing competition,'' in Proceedings of the 2009
IEEE Symposium on Computational Intelligence and Games, CIG 2009,
Milano, Italy, 7-10 September, 2009, 2009, pp. 263-270.

D. Loiacono, A. Prete, P. L. Lanzi, and L. Cardamone,``Learning to
overtake in TORCS using simple reinforcement learning,'' in IEEE
Congress on Evolutionary Computation. IEEE, 2010, pp. 1-8.

Any way, studies with a competitive environment, in this and other
games, have been included in the bibliography and discussed in the
State of the Art section.

	\end{itemize}			
%%%	\end{enumerate}		
		\item {\bf Comment 3:}
		\begin{quote}
		When describing the experiment, the authors stated that in a solo environment, the learning process was based on 20 laps, while using the suggested GPS, learning was based on several races. So, did the authors use 20 laps per race in a competitive environment? In other words, I am curious to see if the training was fair based on the same computational cost.
			\end{quote}	
		\item {\bf Response:} 
		We used the same number of laps in competitive
                environment Thus, results of Table 3 and Table 4 are
                obtained considering 20 laps. This is clarified in the
                table caption.
%		Mohammed
		\item {\bf Comment 4:}
		\begin{quote}
The authors used a two-point crossover operator. Is there any rationale for using a two-point crossover operator? Why not use a one-point crossover or uniform crossover? Further explanation is needed for this.
			\end{quote}	
		\item {\bf Response:} 
Some works, such as the one by Eshelman et al., do not recommend the use of 1X (one-point crossover) due to its clear biasing effect. It presents the so-called positional bias which makes it harder to generate good solutions. On the opposite side the UX (uniform crossover) do not present any bias, however, it lacks the advantages of the building blocks. 2X (two-point crossover) is a good intermediate option among them. Moreover, we conducted in previous works an exhaustive experimentation process in which we tested different alternatives, finding out that 2X yielded the best results.
We have added this explanation to the text (as a footnote on page 6), as well as the reference:\\
Eshelman, Larry J., Richard A. Caruana, and J. David Schaffer. "Biases
in the crossover landscape." In Proceedings of the third international
conference on Genetic algorithms, pp. 10-19. 1989.
% Why a footnote and not in the main text? - JJ

		\item {\bf Comment 5:}
		\begin{quote}
The author used population size = 60, crossover rate = 0.85, mutation rate = 0.09, etc. Is there any rationale for using these control parameters? Can it be argued that these parameters are not optimized for the proposed technique? It is necessary to find the optimal parameters for each comparison technique using grid search, etc., and then compare them.
			\end{quote}	
		\item {\bf Response:} 
		The reviewer is right; these parameters are the optimal ones for our first trained controller GFC which is the baseline for the proposed controllers in this paper. We believe that using the same parameters for the considered techniques is fair for the comparison taking into account that a grid search would be very time consuming. 
		This is highlighted in page 6 of the text like:
		\textcolor{red}{
		We kept the same values for the evolutionary parameters as in our previous works for two reasons: first, because they yielded good results (and are not the focus of
		this paper), and second, in order to compare previous controllers with
		the new ones in the same conditions.}
		
%		Mohammed
		\item {\bf Comment 6:}
		\begin{quote}
It is necessary to examine whether the testing track's performance claimed in the experiment is fair. Since the method proposed by the authors performs training in an already competing environment, there is no guarantee that the test environment is performed completely based on unseen data (test set corruption might exist). If the evaluation is to be conducted fairly, it seems necessary to make changes in the number of competing vehicles, etc.
			\end{quote}
		\item {\bf Response:} We have added a sentence
                  justifying our choice of one of these tracks, {\sf
                    street 1}:
                  there's more space for overtaking, for instance, but
                  also many sharp turns and segments where speed can
                  be maxed up. Our training system, anyway, does not
                  memorize tracks, so we dare say that there's no
                  problem of overfitting to a specific track. There
                  might be a problem of drivers prepared only for
                  specific features: high-speed segments, or other
                  with only mild turns. This is why we select tracks
                  based on the presence of many different features for
                  which our drivers can be prepared. Even so, the one
                  used for testing does have a unique, race-oriented
                  feature (more possibilities of overtaking) that has
                  been highlighted in the new version.

		\item {\bf Comment 7:}
		\begin{quote}
Need to compare with other state-of-the-art algorithms. The authors seem to have only compared the results of their previous studies.				
			\end{quote}	
		\item {\bf Response:} 
		The reviewer is right, indeed we tried to contact many other authors of bots which participated in past editions of the competition, in order to include them in the comparison. Unfortunately, we just received a positive answer from the creators of PSRI bot. Thus, we have also included quite competitive opponents in the comparison, such as \texttt{berniw, tita} and \texttt{inferno}, which have been also considered in many previous studies.

Anyway, most of the experiments are focused on analysing the impact of
the different proposed factors and operators on our previous
approaches, so we use them for comparison.
		
%%		Mohammed
	\end{itemize}

The authors want to thank the reviewer for his/her valuable suggestions for improvement.


\end{enumerate}
 

%----------------------------------------------------------------------------------------

\end{letter}

\end{document}

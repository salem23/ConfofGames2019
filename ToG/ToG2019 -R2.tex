\documentclass[10pt,journal,compsoc]{IEEEtran}
\usepackage[dvipsnames]{xcolor}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{url}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{colortbl}

\def\UrlBreaks{\do\/\do-}
\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
	%\title{Bare Demo of IEEEtran.cls for\\ IEEE Computer Society Journals}
%
\title{Overtaking Uncertainty with Evolutionary TORCS controllers:
  Combining BLX with Decreasing $\alpha$ Operator and Grand Prix Selection}

\author{Mohammed~Salem, Antonio~M.~Mora, Juan~J.~Merelo% <-this % stops a space
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem M. Salem was with the Department of Computer Sciences, University of Mascara, Algeria.\protect\\
% note need leading \protect in front of \\ to get a newline within \thanks as
% \\ is fragile and will error, could use \hfil\break instead.
E-mail: salem@univ-mascara.dz
\IEEEcompsocthanksitem A~M.~Mora was with the Department of Signal Theory, Telematics and Communications, ETSIIT-CITIC, University of Granada, Spain.\protect\\
Email: amorag@ugr.es
\IEEEcompsocthanksitem J~J.~Merelo was with the Department of Computer Architecture and Computer Technology. University of Granada, Spain.\protect\\
Email: jmerelo@geneura.ugr.es
}% <-this % stops an unwanted space
\thanks{Manuscript received December XX, 2019; revised XXXX, 2020.}}


\IEEEtitleabstractindextext{%
  \begin{abstract}
    Evolution is a powerful problem-solving technique, extensively
used for designing racing car controllers, but with a series of
challenges: an evaluation function that is able to separate the best
controllers from the rest, and a series of operators that are able to
explore different possibilities in the controller search space. Within
the context of the TORCS racing simulator, in this paper we introduce
a kind of fitnessless selection policy based on competition and called
\textit{Grand Prix Selection} (GPS), which will be able to reduce uncertainty by using something more realistic than solo race scores to
select individuals. Additionally, we increase the exploitative power
of this kind of selection via a BLX operator with continuously decreasing $alpha$. We
compare these new selection and operator with hybrid approaches that
apply GPS only part of the time, as well as other classical crossover
operators. In general, experiments show that these combined
improvements establish a new level of performance of evolved
controllers, being able to beat, both standard and previously evolved
ones, as well as a high-ranked controller of TORCS competitions.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Simulated Car Racing, TORCS, Fuzzy Controllers, Autonomous
controllers, Genetic Algorithms, Optimization, BLX-$\alpha$ Crossover,
Grand Prix Selection, Fitnessless, Uncertainty, Competitive fitness 
\end{IEEEkeywords}}

% make the title area
\maketitle


\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle

%%%%\textcolor{red}{

\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}
\textcolor{red}{
Driving a simulated car can be formulated as an optimization problem in which you have to map inputs that include data about the driving environment as well as car data, to the output: throttling and steering. This mapping has 
 to meet a series of standards: cars should not crash and should have a
reasonable speed \cite{Autodriv2006}.} Additionally, in a racing car the controller has to be designed so that the car wins in as many races as possible.

Since there are so many variables in this problem, the search space is usually reduced using heuristic rules. For instance, deciding the type of controller is usually done before the design process begins, and a single, parametrized one
is chosen; fixed rules as well as neural networks \cite{KIM201287} or fuzzy controllers \cite{PerezEvolvingFuzzy09} are often used. \textcolor{red}{
Additionally}, training (or learning) \cite{Loiacono:2012:LEA:2212908.2212953} can be done online (during the
race), so that it can adapt itself to new and previously unseen,
scenarios and competitors, or it can be fixed training offline. 

We have been using genetically-optimized fuzzy controllers in this line of work, with increasing success \cite{salem_evo17},\cite{salem_evo18}.
However, in a simulated and realistic racing car environment like the one we use, racing car scores are a
    statistical variable whose value will vary depending on track and
    (simulated) atmospheric conditions; and we should never forget
    that score in a training track will always be a surrogate of its
    actual score when racing against other cars on different tracks,
    which adds another layer of uncertainty, making this a {\em noisy} optimization problem.
If training is done before the
    race, and the controllers are fixed via an optimization process,
    the uncertainty in the evaluation of every controller will make
    the resulting score in unknown tracks with unknown rivals
    uncertain at best.

\textcolor{red}{A potentially useful} way to reduce uncertainty is to make the evaluation process
as close as possible to the environment in which the controller will
eventually compete, in a race with other competitors. 
\textcolor{red}{
	If we can eliminate fitness, we can remove a source of uncertainty. We accomplish this by substituting a single (and uncertain) fitness  by a podium (a ranking after several races against other opponents) 
	in which car controllers that win the most races will proceed to the next generation, while those that do not, will simply be removed from the pool. We can further reduce uncertainty even more by repeating
	races several times."
}


By totally eliminating \textcolor{red}{individually-computed} fitness
\textcolor{red}{and moving to} a ``fitnessless'' environment, we also
eliminate \textcolor{red}{one} source of uncertainty,
\textcolor{red}{which is reduced further} by repeating the races
several times. A single (and uncertain) fitness is thus substituted by
a podium (a ranking after several races against other opponents) in
which car controllers that win the most races will proceed to the next
generation, while those that do not, will simply be removed from the
pool.

\textcolor{red}{By doing this, we try to overcome one of the biggest
challenges we have found in this line of research. Uncertainty in
selection was already identified as such in its first paper
\cite{salem_evo17}, which introduced} a basic
\textcolor{red}{fuzzy-controller based car driving}
system. \textcolor{red}{This system was iteratively improved in
\cite{salem_evo18,salem_ipmu18}, by using an EA to change the shape
and values of the fuzzy controllers}. However, we still had to deal
with uncertainty, as well as a suboptimal exploration of the parameter
space; the main issue was that we were using a surrogate
\textcolor{red}{to measure the performance} of the bot by doing solo
races, \textcolor{red}{and we tried to make that surrogate as accurate as
  possible by testing} different
fitness functions, but also, in \cite{salem_cig2018}, by racing the best individuals in the last
generation. Introducing
races in the selection of the ``winner'', even if it was in the last
generation, improved results, so this kind of competitive selection
was extended by introducing real races from every few generations in
\cite{DBLP:conf/cig/SalemMG19}, where we also applied the BLX-$alpha$
operator, and checked two different configurations using a fixed and a
decreasing $\alpha$. This operator combines exploration and
exploitation, and lets the designer establish the balance between both factors in the search. The
results with decreasing $\alpha$ were the best obtained so
far. \textcolor{red}{Although this additional operator, by itself, did
  not reduce uncertainty in the selection of individual car
  controllers, by enhancing search capabilities it made possible
  accessing parts of the search space where controllers with low
  uncertainty could possibly be found}.

Thus, in this paper we are testing the best approaches we have found all together in an algorithm, considering a kind of fitnessless selection, which we have called \textit{Grand Prix Selection} (GPS). Although this selection uses a score that could be assimilated to a fitness, it is actually an extension of a tournament selection policy since it creates tournaments of several individuals, and ``scores'' them according to how they fare in these races. This is not actually a fitness, since it is not intrinsic to the individual. It is indeed equivalent to,\textcolor{red}{ in an $n$-tournament} selection that is repeated several times, giving a score of $n$ to the first, $n-1$ to the second, and then using this for selection. That score is, thus, not a fitness but actually a way of keeping track of the position of the individual in the different tournaments it has participated; since, in this context, we have no way of evaluating (i.e. assigning a fitness) to a controller but only a way to compare them, we call this approach {\em fitnessless}, as it was called, for instance, in \cite{jaskowski2008winning}.
This selection policy is combined with other policies or by itself, as the only way for car controllers to be selected for the next generation.

This work also presents an exhaustive study, where we have checked how this Grand Prix Selection works compared with mixed fitnessless and fitness-based races, or simply using a selection for those controllers that have the highest fitness in the last generation.  
This reduction of uncertainty has been proved also to reduce diversity in the genetic pool \cite{DBLP:journals/tcci/MereloLFGCCRMGTCC16}, which is why the introduction of the \mbox{BLX-$\alpha$} operator, with a certain explorative component, achieves better results than GPS by itself, as we will show here.
In addition, we have compared the influence of the \mbox{BLX-$\alpha$} operator on the performance of the evolved controllers with others using standard crossover operators, since we aim to better control the diversity in the population.

The rest of the paper is organized as follows. Next we present the
state of the art, to be followed by a description of the TORCS
simulator and the previously defined fuzzy controllers in Section
\ref{sec:methods}. After this, the evolutionary algorithm implemented
is explained in Section \ref{sec:ga}, including an extensive explanation of the new selection policy as well as the BLX-$\alpha$ crossover operator. After it, the experiments conducted and the obtained results are described in
Section \ref{sec:results}. Finally, conclusions and future lines of
work will be presented in Section \ref{sec:conclusions}. 





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  STATE OF THE ART  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{State of the Art}
\label{sec:soa}


% We have to focus the state of the art in three different things
% 1. First and foremost, uncertainty in evolution, since it's in the
% title of the paper.
% 2. Second, alternative selection operators used in games, similar to
% the Grand Prix Selection.
% 3. State of the art in TORCS since our last paper (CoG 2019)

The problem of designing controllers for racing cars has been
approached using soft computing since the first papers were
published; however, they differ in the way the specific controlled
works. In many cases, they learn during the race; reinforcement
learning has that specific capability, and it was used by Loiacono et
al. \cite{loiacono2010learning} in the first paper that uses it. It is still one of the most popular methods, as is shown
in recent papers like \cite{giani2019desing,remondaformula,waghdistributed}; in the last case, the method used is called asynchronous advantage actor-critic
reinforcement algorithm.

However, it is not the only kind of soft computing method
used. \cite{mirus2019short} uses a neuromorphic architecture, namely,
spiking neural networks, but using, the same way we do in our works, a single track for training. The kind of data used for the design of racing cars is
also different depending on the author. 
According to our previous works \cite{salem_evo17},\cite{salem_evo18},\cite{salem_cig2018},\textcolor{red}{ in general, successful racing could be achieved using only these sensor values }to drive the car, since they give enough information to avoid collisions, drive as close as possible to the center of the track, and drive as fast as possible.

Other soft computing methods have been combined also with evolutionary algorithms in several occasions, such as \cite{10.1371/journal.pone.0213193} which uses neuroevolution. \textcolor{red}{Thus, controllers trained in one track are briefly re-trained for use in other tracks}, in what is called ``transfer learning''. This is also the technique applied by the authors in \cite{verma2018programmatically}. 


Evolution can also be used directly to compute the optimal trajectory after ``test laps''. This is what Vrajitoru does \cite{vrajitoru2019trajectory},
%\cite{vrajitoru2019trajectory,vrajitorugenetic}, 
%%% Antonio - I remove one reference to save space.
using then an evolutionary algorithm to optimize driving within that specific track and considering the obtained trajectory calculation. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TORCS  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

All the different approaches would not have been possible without a
racing car simulator that could be the testbed for them all, which was
TORCS (The Open Racing Car Simulator) \cite{torcs4}. The TORCS racing simulator
continues to be one of the main platforms  
for testing different autonomous driving or bot creation strategies,
which are, by and themselves, also a hot topic in the gaming arena as
well as by itself, at least since DARPA created their autonomous car
challenge \cite{badue2019selfdriving}.


Only in the last year (2019) there are around 200 articles that
mention TORCS; \cite{schiavullo2019torcs} revises its applications for the last 20 years. It can be considered as the most successful platform used for this kind of problem.

Fuzzy controllers are mentioned in around 15\% of the above mentioned articles, while around 30\% mention evolutionary algorithms; very few, however, around 7\%, use both, and most of them are not actually using TORCS (but just mentioning it); so the approach in this line of research is truly original in this context.

There are several possible approaches to autonomous driving and its
solution using TORCS, such as neural networks or reinforcement learning \cite{abuzekry2comparative}. 
You can also use vision to have more complete, although more complicated, view of where the car is and where it is going, or just use sensors, which on one hand check the most immediate scenario, but on the other hand are more precise and easy to process.

In our case, we have opted for the latter, although other authors like Zhu et al.
\cite{zhu2019vision} rather
%%\cite{zhu2018driving,zhu2019vision,neurone} rather 
%%% I deleted this ref to save space %% Mohammed
%%% Antonio - I also remove another one to save space. ;)
consider vision, using TORCS as a testbed for a different kind of
algorithms. On the other hand \cite{8833873} uses deep learning, working with real images instead of sensor values, whereas \cite{Kaushik_2018_ECCV_Workshops} describes a DDPG (deep deterministic policy gradient) that uses images to learn behaviors for specific racing scenarios.

TORCS, being a realistic simulator, is able to introduce `noise' into
the track conditions, so that races will never be the same. In
general, this is the case for most games: there are sources of
uncertainty either in the game environment itself, or in the behavior
of non-playing characters that act as adversaries in the game; the
game bot or controller itself can also have non-deterministic rules,
which is an additional source of uncertainty. Plus games are games,
and the best way of checking how well a bot or controller plays, is by
playing the game. This way of evolving bots was called fitnessless
coevolution: and was defined in
\cite{Jaskowski:2008:FC:1389095.1389161}. This is a precedent to our
Grand Prix Selection, presented here, whose essence is
to get rid of a fitness score resulting from evaluation of an
individual, substituting it by a score obtained by the controller in
more realistic competitive conditions.

The concept, however, goes back at least to
\cite{Angeline:1993:CEE:645513.657590}, which calls it a ``competitive
fitness environment''. Fitnessless evolution was further developed in
\cite{rosin1995methods}, but it has been also used in genetic
programming by Tettamanzi in \cite{tettamanzi1996genetic}.

However, the competitions played in those works were not, strictly,
games. The first time fitnessless evolution was used in  games was by
\cite{luke1998genetic}; however, it was later used extensively, like
%\cite{Jaskowski2008,10.1007/978-3-540-78671-9_2,alhejali2011using,fernandez2016_only_one}. 
\cite{Jaskowski2008,10.1007/978-3-540-78671-9_2,fernandez2016_only_one}.
% Antonio - Reducing the number of references. Changing our ref to another shorter => Save space
Deriving which individuals are the best from these races, taking into account
the {\em noisy} environment we have mentioned, is not trivial
either. As recently as 2017, an ELO-based ranking strategy was
introduced for selecting winning bots in a fighting game
\cite{7792145}. The first one mentions ``imperfect information'',
precisely, as one of the factors to use this fitnessless strategy.

Since we are working with racing games, we will introduce a score that
is closer to the one used in that kind of games. This will be
presented after the rest of the methods and tools used in this paper. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%  METHODS  %%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Methods and tools}
\label{sec:methods}

This section presents the environment where the study has been conducted, i.e. the simulator TORCS, as well as the fuzzy sub-controllers designed in previous works and which will be the `target' of the optimization process conducted in this paper. 

%-------------------------------  TORCS ----------------------------
%

\subsection{Simulation environment}

\begin{figure}[!ht] 
	\begin{center}
		\includegraphics[scale=0.26]{fig/torcs-sensors}
		\caption {TORCS capture showing some of the sensors
                used by the autonomous drivers (controllers). Figure from \cite{DBLP:conf/cig/SalemMG19}.}
		\label{fig:torcs-sensors}
	\end{center}
\end{figure}

\textcolor{red}{
We are using in this study The Open Racing Car Simulator (TORCS) \cite{torcs4}, which is free software, and offers realistic physics, as well as telemetry that is used by the car controllers to gauge their position with respect to the track, the position of the rest of the players, and self-measurements like speed, damage incurred or angle. These measurements are connected to car sensors \cite{torcs5}, which are represented in Figure \ref{fig:torcs-sensors}. TORCS provides these sensor values as input to the car controller and these will be
used to manage the car by means of actuators such as brake, accelerator, steering wheel or gearbox. 
This simulator has been used in many other studies in the area of autonomous driving or simulated racing car evolution.}

%All these sensors refer to different angles. The sensors considered in this work are:
%\begin{itemize}
%	\item Sensor 9 (frontal distance): straight distance to the track border (or another vehicle) in an angle of 0\textdegree.
%	\item Sensor 8 and Sensor 10: distance to the track border (or another vehicle) in an angle of +5\textdegree and -5\textdegree with respect Sensor 9.
%	\item Sensor 7 and Sensor 11: distance to track border (or another vehicle) in an angle of +10\textdegree and -10\textdegree with respect to Sensor 9.
%\end{itemize}

Other open source simulators, mentioned in \cite{Loiacono:2012:LEA:2212908.2212953}, are also available: VDrift
if more focused in 3D realism, and Speed Dreams is actually a fork of
TORCS, same as Gym-TORCS \cite{yoshida2016gym}, which is a Python
wrapper which is specially designed to test controllers based on
reinforcement learning.

Although our results are not TORCS specific, we have been
working on this since it has got all the telemetry and simulation
tools that we need, and besides it has been repeatedly used in
competitions, so it is a good testbed to evaluate the performance of new controllers, in case the competitions came back.

TORCS does not impose a specific way for programming the controllers;
it can be done via any system that maps inputs to outputs. We decided
to use fuzzy sub-controllers, which will be described next.

%---------------------------  FUZZY SUB-CONTROLLERS ----------------------------

\subsection{Fuzzy sub-controllers}
\label{subsec:fuzzy-controllers}

\begin{figure}[!ht]
  \begin{center}
    \includegraphics[width=9cm]{fig/flowchart}
  \end{center}
  \caption{Schema of the two controllers that will be evolved by the proposed 
    evolutionary algorithm (GA), and evaluated by TORCS, which will
    return the values for the car's average speed on the complete race and the incurred damage on the vehicle. Figure taken from \cite{salem_evo18}.} 
    \label{fig:ga}
\end{figure}
%
The two fuzzy sub-controllers we evolve take care of target speed and steering angle. These controllers were introduced by the authors in a previous paper \cite{salem_evo17}, and share the same structure as the standard TORCS driver but they consider five different sensors (see Figure \ref{fig:torcs-sensors}). These controllers are shown in Figure \ref{fig:ga}. 


The \textit{speed controller} takes as input sensor values, and
outputs the target speed; aiming to maximize it straight parts and curves of the circuit. The \textit{steering controller} uses the same sensor values to output the optimal steering angle in order to reach the desired target position with the car.

The two sub-controllers use the same three linguistic variables as
inputs, one for every sensor: one for the frontal sensor,
\texttt{FRONT}, another for Sensors 8 and 10 ($\pm 5$\textdegree),
\texttt{MAX5}, and finally from Sensors 7 and 11 ($\pm
10$\textdegree), \texttt{MAX10}. These variables compose a Mamdani-based fuzzy
system \cite{iancu2012} with three trapezoidal Membership Functions
(MFs) for each variable. The controller uses a set of fuzzy rules
which combine the fuzzy values for these inputs to compute outputs:
target speed or steering angle.
% 
% Antonio - I move this text and tables to the sub-controllers section, since these variables have been defined to be used in the fuzzy rules. Moreover, the variables are introduced for the first time in this section. 
These rules were designed following usual human-like race car driving
rules in \cite{salem_evo18}, are fixed and shown in Table \ref{tab:output}.


\begin{table}[h!tb]
  \centering
  {\scriptsize
    \caption{Rules  (from \cite{salem_evo18}) for speed (top) and steering
      (bottom) controller output. Additionally, when 
      the front, right and left sensors have the maximum value
      possible, a crisp rule that tries to set the max speed
      fires.  Angles will be reversed
      if the M10 is equal to Track 7 in the steering controller. The
      actual output will be the centroid of the output of all functions
      that are activated. \label{tab:output}}
    \begin{tabular}{|c|c|c||c|}
\hline
      Value FRONT & Value MAX5 & Value MAX10 & Target Speed (km/h) \\
      \hline
      High & - & - & 280 \\
      Medium & - & - & 240 \\
      Low & High & - & 220 \\
      Low & Medium & - & 180 \\
      Low & Low & High & 120 \\
      Low & Low & Medium & 60 \\           
      Low & Low & Low & 30 \\     
\hline
%\end{tabular}
%\begin{tabular}{|c|c|c||c|}
\hline
      Value FRONT & Value MAX5 & Value MAX10 & $sin$(Steer Angle) \\
\hline
      High & - & - & 0 \\
      Medium & - & High & 0.25 \\
      Medium & Medium & Medium & 0.25 \\
      Medium & Low & Medium & 0.5 \\
      Low & - & High & 0.5 \\
      Low & Medium & Medium & 1 \\
      Low & Low & Medium & 1 \\ 
      
\hline
\end{tabular}
}
\end{table}



Thus, what will be evolved with the algorithm proposed in Section
\ref{sec:ga} is the shape of the whole fuzzy system, which is encoded
in 18 real-valued parameters (related to the different membership
functions). The low-level details of this part was explained
extensively in \cite{DBLP:conf/cig/SalemMG19}. 

As mentioned, these fuzzy sub-controllers proved to be a good platform for the evolution of racing car controllers, and have not essentially changed since our first paper. As a matter of fact, the methods presented in this paper could
be applied to any kind of controller, as long as it can be fully
encoded and evolved using an Evolutionary Algorithm. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%  OPTIMISING WITH GAS  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Optimizing Sub-controllers with an Evolutionary Algorithm}
\label{sec:ga}

We have applied an evolutionary algorithm (EA) \cite{EAs_Back96}, to optimize the parameters of the membership functions of the fuzzy sub-controllers we have used in this line of research.
% Antonio - I put this text back as we are working with a GA (the title of the section says this), so it is clearer to say what is it. Moreover, the reference is also used in other places, so it is not removed to save space indeed. 
% In addition, there is free available space now. ;)
% You don't way why this is a GA and not an EA, and why it's relevant
% to make this distinction. But whatever. - JJ

EAs are nature inspired methods that evolve populations of possible (encoded) solutions for a problem following a process of selection of the best,
recombination and mutation, in order to create a new population of
better individuals on average. This is repeated a number of times
(generations) to get to a solution that meets our requirements, or the
budget we have for evaluation of solutions. EAs have been widely
applied to solve a huge amount of optimization problems, including regression and fuzzy systems \cite{hoffmann2001evolutionary}; in this kind of problem the solutions are modelled as a vector of numeric values, as is the
case in this paper; we use 18 floating-point values, 6 per variable, 2 values per membership function.


% We show in Figure \ref{fig:cromosome} how we represent every individual (chromosome) as a vector of 18 values/parameters (genes), 6 per variable. They have been coded using real values, looking for higher precision \cite{elsayed13}. We started to use this encoding in \cite{salem_evo18}.


%  \begin{figure*}[!ht]	
%  	\begin{center}
%  		\includegraphics[width=12cm]{fig/chromosome2.png}
%  		\caption{GA chromosome description. There are 6 genes
%                   (values) per fuzzy variable, modelling the 3
%                   different membership functions. The membership
%                   functions are trapezoidal, needing only two values
%                   for every one.}
%  		\label{fig:cromosome}	
%  	\end{center}	
%  \end{figure*}

% \begin{figure*}[!ht]	
% 	\begin{center}
% 		\includegraphics[width=12cm]{fig/chromosome2.png}
% 		\caption{GA chromosome description. There are 6 genes
%                  (values) per fuzzy variable, modelling the 3
%                  different membership functions. The membership
%                  functions are trapezoidal, needing only two values
%                  for every one.}
% 		\label{fig:cromosome}	
% 	\end{center}	
% \end{figure*}



Following standard implementations in the first step of the algorithm \cite{salem_evo18} a
population of random individuals is composed by assigning diverse values inside a feasible range ($[0,100]$).

In general, an evolutionary algorithm will need to evaluate every
individual so that they can be compared with each other and decide
which ones will go ahead to the next generation. We use TORCS for this
purpose, as is shown in Figure \ref{fig:ga}: out of the encoded fuzzy
MF values we create a controller, that is assigned to the car, but
evaluation is done in two different ways.

The first method considers the fitness function already used
previously \cite{salem_cig2018}, because it was the most successful 
among some others proposed \cite{salem_evo18}. It is described as: 

 \begin{equation} \label{fit_avg}
 	\begin{array}{lll}
 		f_{AVS}= \frac{AVG(Speed)}{Damage+1}
 	\end{array}
 \end{equation}	

Where $AVG(Speed)$ is the average speed of the car along the complete
race. This factor represents the overall performance of the controller
combining difficult (e.g. curves) and easy (e.g. straight) parts of
the tracks. $Damage$ value is taken into account in order to preserve
the car integrity, which is required to finish the race. 

Following the usual recommendations in the literature
\cite{Harik-ParameterLess99}, we have defined a parameterless
selection method, where there are no weights in the terms.
At the same time, this way of evaluating different cars is closer to a `human-like'
approach, since it considers the same prioritary factors that a human
driver would do.

That fitness is computed in a solo race with 20 laps in the chosen circuit. In this paper, however, we also introduce Grand Prix Selection or GPS. In this
selection, a controller is evaluated in terms of races with the rest
of the controllers in the same generation. Fitness is then not
computed directly from telemetry in a solo race, but out of the score
obtained in a championship with several races, where every controller
in a generation participates. This will be describe more extensively
in the next subsection.

\textbf{non uniform mutation} \cite{mutation1997} has been used as the
\textit{mutation operator} in the GA, because it was considered in
previous approaches of our controllers. 

The next section will describe the two methods we are presenting in
this paper: a fitnessless selection policy and an extended real-value
crossover operator able to manage the balance between exploration and
exploitation during the evolution. 

% -------------------------------------------------------------------
\subsection{Grand Prix Selection and decreasing-$\alpha$ BLX blending crossover operator}
\label{subsec:novel_operators}

As introduced in the previous subsection, the \textbf{Grand Prix Selection} policy (GPS)  aims to select, in every generation, more reliable individuals/controllers as parents to combine their genes for creating new individuals in the following generation of the algorithm, as well as use them as a basis for exploration of new solutions. It is a fitnessless approach,
independent of the aforementioned fitness function (see Equation
\ref{fit_avg}), designed to better deal with the uncertainty present
in the election of an actual good individual using solo races, which
is a good surrogate for the actual objective of evolution, winning
competitive races, as has been proved in our papers so far. However,
in this paper we will examine if using real races for evolution can be
a better option in terms of performance, and also of evaluation
budget. 

The mechanism arranges groups of 10 individuals/controllers which are placed in a track in TORCS, where different races are simulated. Thus, they compete, using the same car (i.e. in the same conditions) during several laps. After every race, the controllers get a score according to their position in the final rank. This is a \textit{score function} based in Formula 1 Grand Prix ranking, so the obtained scores per rank are: rank 1 - 25 points, 2 - 18, 3 - 15, 4 - 12, 5 - 10, 6 - 8, 7 - 6, 8 - 4, 9 - 2, 10 - 1.
Then, the best individuals will be those whose accumulated score (sum of scores of all races) are the five highest.

The objective of this operator is to really select the best
individuals of the population. However, given the existing uncertainty
\cite{merelo2016statistical} due to the competition against other
non-deterministic controllers, it is not possible to ensure they are
doubtlessly the best. 

In this respect, the authors argue that this operator will provide better individuals than one based on a `standard' fitness function, regarding their competitiveness and reliability. The reasoning for this is the fact that their score just depends on their ability to win the race against other competent controllers, rather than in the combination of a set of variables which might add `noise' to the valuation of the individuals.

However, the application of this method consumes much higher computation time, so it could be combined with a classical fitness-based selection in some generations. Indeed, in the experiments conducted in Section \ref{sec:results}, we have analyzed the impact of the application of different configurations of GPS, considering different frequencies of application during the evolutionary process.

The second operator implemented in our GA is the Blend Crossover or \textbf{BLX-$\alpha$ Crossover} \cite{blx2008} introduced originally by Eshelman and Schaeffer \cite{eshelman1993real}, and adapted here to use a varying $\alpha$ value. As stated before, one of the side effects of uncertainty is its derived higher diversification factor. Thus, in order to have a better control between the exploration and exploitation factors during the evolution, the balance changes with the decreasing value of $\alpha$.

It is based on the random selection of values from the interval
$[x_i-\alpha(y_i-x_i).. y_i+\alpha(y_i-x_i)]$, where $x_i$ and $y_i$
are the $i^{th}$ parameter values of the parent solutions $x$,$y$ and
$x_i < y_i$. % See Figure \ref{fig:blxalpha}.

% \begin{figure}[!ht]	
%  	\begin{center}
%  		\includegraphics[width=7cm]{fig/blxalpha.jpg}
%  		\caption{Blend crossover operator ($BLX-\alpha$). Figure taken from \cite{Adibo_BLXFig_03}.}
%  		\label{fig:blxalpha}	
%  	\end{center}	
%  \end{figure}
%  Antonio - I include again the figure, because I consider it as very ilustrative to understand how BLX-alpha works. And now we have enough free space.
% It's not the objective of the paper, and it's not even our figure. - JJ

Thus, this crossover method was designed for real-coded EAs \cite{blx2008}, and creates the offspring (i.e. individuals of the new generation) of the current population by selecting random values for every gene around an interval for each of the parents' genes. So, it is able to create three new individuals from one parent, which are different between them and, of course, different to their parent individual. This fact enhances the exploration factor in new generations.

The value of the $\alpha$ parameter regulates the exploration/exploitation balance when searching the space of solutions; a value $\alpha = 0.5$ will balance exploration and exploitation.

Given the characteristics of an evolutionary algorithm and the way it works, the first generations should be devoted to explore the search space looking for promising areas (those with potential good solutions) where parts of the population could be focused. This would be done by means of a diversification in the individuals. Then, a exploitation process would be recommended, in order to refine the promising solutions to get to an optimal one.

To this end, we have implemented an \textit{BLX} operator with a decreasing $\alpha$ value, following
the expression: \mbox{$\alpha =1-\frac{g}{g_{max}}$}, where $g$ is the
current generation and $g_{max}$ is the maximum number of generations.

This will mean a higher diversification factor in the first generations, because the offspring will take much more different values for their genes in comparison with their parent and other descendants. %, i.e. the intervals in Figure \ref{fig:blxalpha} will be wider. 
% Antonio - Referencing again Figure. Anyway, the text without this reference was not correct.
On the contrary, as the number of generations is increased, $\alpha$ will take a smaller value, the intervals will be reduced, the individuals will be more similar to their parents, and thus, the space of solutions will be exploited (the solutions will be refined).

We argue that this operator, in conjunction with GPS will aid the
algorithm to find better controllers, so we will test several
combinations and configurations of both techniques in the experiments
conducted in next section. We will also study their impact from
different perspectives, both considering their performance and also
from the uncertainty influence point of view. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%  RESULTS  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments and results}  
\label{sec:results}

% >>>>>> TODO: Explain the new experiments and results -> Mohammed  <<<<<<<<<<
% TODO: Results with GPS (no BLX-Alpha crossover)
% TODO: Results with GPS and BLX-Alpha crossover
% TODO: Comparison against the standard controllers in TORCS
% TODO: Comparison against S&PL controller (of all our controllers, if possible)
%
%\begin{figure}[!ht]	
%	\begin{center}
%		\includegraphics[width=3cm]{fig/alpine2.jpg}
%		\includegraphics[width=3cm]{fig/wheel2.jpg}
%		\caption{Alpine 2 Track. Length: 3773.57m, Width: 10m.}
%		\label{fig:alpine2_track}	
%	\end{center}	
%      \end{figure}
%%     
\begin{figure}[!ht]	
\centering
\begin{subfigure}[b]{0.15\textwidth}
	\centering
	\includegraphics[width=2.5cm]{fig/alpine2.jpg}
%	\caption{Alpine 2 Track.  Length: 3773.57m, Width: 10m.}
	\label{fig:alpine2}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.15\textwidth}
	\centering
	\includegraphics[width=2.5cm]{fig/wheel2.jpg}
%	\caption{\textcolor{red}{Wheel 2 Track.  Length: 6205.46m, Width: 12m.}}
	\label{fig:wheel2}
\end{subfigure}
\caption{Training tracks. Left: Alpine 2; Right: Wheel 2.}
\label{fig:alpine2_wheel2track}
\end{figure}

In this kind of problems, it is essential to select the correct
training track so that bots are able to work in a wide range of
conditions. Since using several tracks would make evaluation too onerous, we chose to select two tracks to train our solution. The first track is \textit{Alpine 2} track, the one already used in several papers  \cite{salem_cig2018,DBLP:conf/cig/SalemMG19}. This circuit has several characteristics that
are essential for evaluating a bot: \textcolor{red}{it has many turns}, some of
them with 180 degrees, steep segments, and some very challenging parts
like the entrance of a tunnel at a square angle.\textcolor{red}{ These features} make
it a good testbed for good turning and collision avoidance
strategies. Moreover it also offers a few straight segments which allow the car to speed ahead, reaching high speeds. This same track has been also repeatedly used by other authors for training as well as for testing and has been described as ``technical and complex'' \cite{AG} and ``presenting a challenge even at low speeds'' \cite{vrajitoru2018global}, for instance in
\cite{cardamone2010applying,CarRacing_Pelta09,zong2017obstacle}; in \cite{AG} it had the third lowest lap time, after \mbox{Alpine 1} and Olethros, implying it
has got a good balance between hardness and speed. Since we also used
it in our previous papers, it allowed us to compare racing bots that
had been ``trained'' in the same conditions.

\mbox{Alpine 2} track is probably one of the most popular tracks used for
training; \mbox{CG-Track 2} has similar features, and it is used by
\cite{mirus2019short,8833873,verma2018programmatically},
in this last case for transfer learning. \cite{Kole-ParamCarTunning12}
mentions \mbox{CG-Track 2} is ``relatively harder'', with \mbox{E-Track 3} the
hardest. On the other hand, \cite{10.1371/journal.pone.0213193} uses
\mbox{CG-Track 1}. There are several differences between \mbox{CG-Track 2} and \mbox{Alpine 2}, the one we use, but the main one is that turns are relatively
easier and straight segments are longer, favoring fast cars over
balanced ones; this is why we have chosen Alpine 2 for training, since
it offers the best generalization for cars trained using it.\\
The second circuit is the \mbox{Wheel 2} Track. It is a  Suzuka F1 track that combines many challenges such as high speed parts and different curves types. Moreover the eleventh turn is a hairpin turn. It was  described in \cite{wheel2track_chen} as `a more difficult track with many fast turns' (See Figure \ref{fig:alpine2_wheel2track}).
% this figure has disappeared - JJ
% Antonio - Fixed
To test the obtained controllers, we considered two tracks: the first track is \mbox{\textit{E-Track 5}}, used in previous papers \cite{salem_evo17},\cite{salem_evo17} \textcolor{red}{and the second one is \mbox{\textit{Street 1}}.
This }controller has many long speed segments, difficult sharp turns. In addition, the track is two meters larger than the others  three considered tracks which increase the overtaking possibilities.

We have again used the vehicle \mbox{\textit{car1-trb1}},
which is a well balanced, NASCAR type car \footnote{See description in
  the TORCS racing board web page,
  \url{http://www.berniw.org/trb/cars/car_view.php?viewcarid=5}},
which we have used also in our previous papers, and also by many
winning bots along the history of the TORCS championship
\cite{torcs5} as well as other authors in the literature
\cite{auteur2010,li2019reinforcement}. This matches well the selection
of racing track, but being as it is a balanced car, allows driving to
fit itself to the controllers we are developing.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textcolor{red}{
To analyze the influence of the new introduced Grand Prix Selection
(GPS) and the crossover operator on the performance of the fuzzy
controller, we have carried out two main optimization processes based
on the GPS: the first one uses the GPS with the two point crossover
operator while the second uses  BLX with decreasing $\alpha$.
In every process, three controllers are obtained depending on the application of the GPS: in every generation (E), every 5 generations (5) and in the last generation(L). The acronym VA  stands for "varying $\alpha$" in the names of  controllers with BLX and decreasing $\alpha$.
Hence, we experimented six controllers in all: the new
proposed controllers {\sf GFC-GPSVAE} and {\sf GFC-GPSE}, our previous four GPS based controllers \cite{DBLP:conf/cig/SalemMG19}: {\sf{GFC-GPS5}}, {\sf{GFC-GPSL}},{\sf{GFC-GPSVA5}} and {\sf{GFC-GPSVAL}}..
Also and for comparison purpose, two reference controllers have been considered: {\sf{GFC-VA}}\cite{DBLP:conf/cig/SalemMG19} and {\sf{GFC}}\cite{salem_cig2018}, they both use the fitness function $f_{AVS}$ (Equation \ref{fit_avg}) value for selection.
All these controllers are summarized in Table \ref{tab:drivers}. 
}

We have run the algorithms with a population size of 60
individuals. The rest of parameters are: Generations=50, Crossover
rate=0.85, Mutation rate=0.09, and 10 different runs per
configuration. % Clarify if crossover rate means BLX-alpha crossover
               % or there's another crossover too - JJ
              
For every optimization's race, the track is selected randomly from Alpine2 and Wheel 2 tracks.
We kept the same values for the evolutionary parameters as in our previous works for two reasons: first, because they yielded good results (and are not really the focus of this paper), and second, in order to compare previous controllers with the new ones in the same conditions.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This table could be reduced to 1 column - JJ
\begin{table*}[!htp]
	\centering
	{\scriptsize
		\caption{ Description of the controllers tested in the experiments.}
		{
			\begin{tabular}{|c|c|c||c|}
				\hline
				Controller&Fitness & GPS frequency&Crossover operator \\
				\hline
				\hline
{\sf{GFC-GPSE}}&Fitnessless&Every generation&Standard crossover\\
{\sf{GFC-GPSVAE}}&Fitnessless&Every generation & Varying BLX$-\alpha$\\

{\sf{GFC-GPS5}}\cite{DBLP:conf/cig/SalemMG19}&Hybrid&Every 5 generations&Standard crossover\\
{\sf{GFC-GPSVA5}}\cite{DBLP:conf/cig/SalemMG19}&Hybrid&Every 5 generations & Varying BLX$-\alpha$\\

{\sf{GFC-GPSL}}\cite{DBLP:conf/cig/SalemMG19}&Hybrid &Last generation &Standard crossover\\
	
{\sf{GFC-GPSVAL}}\cite{DBLP:conf/cig/SalemMG19}&Hybrid &Last generation & Varying BLX$-\alpha$\\
{\sf{GFC}}\cite{salem_cig2018}& Fitness $f_{AVS}$ (Equation \ref{fit_avg})&-&Standard crossover\\							
{\sf{GFC-VA}}\cite{DBLP:conf/cig/SalemMG19}&Fitness $f_{AVS}$ (Equation \ref{fit_avg})& - & Varying BLX$-\alpha$\\


\hline
				
			\end{tabular}
		}\label{tab:drivers}
	}
\end{table*}
%

% ---------------------------------------------------------------------------

\subsection{Uncertainty in fitness evaluation}

We need first to find out how different kind of selection procedures
affect uncertainty in scores (fitness values). Better selection procedures should be able to reduce it, making evolved controllers as centrally distributed
as possible; other kinds of selections should keep distribution of
scores (for a single controller) skewed and lopsided; this is why we
have done a study of the distribution of the genetic individuals of
three approaches: {\sf GFC}, {\sf GFC-GPSE} and {\sf GFC-GPSVA5}. 


Skewness is related to how symmetric the distribution of fitness
scores is. There are several strategies that deal with this kind of
uncertain (usually called {\em noisy}) fitness functions; but a simple
one is to re-evaluate ({\em re-sample}) the score every generation. A
skewed distribution mean that it will more likely to sample a value
that is different from the average, but it might be better or worse
than average; in any case, different from the (crisp) score we would expect to
achieve in other circumstances. On the other hand, kurtosis measures
the amount of values that are far from the average, creating either a
heavy-tailed or too-lightly-tailed distribution. In the first case, it
will mean that values far from what would be expected (the median or average) are likely to
show up in the fitness score.

This is why we are interested in how these two statistical measures
are going to change with evolution using the different fitness measures; skewness and kurtosis will  affect
selectability of an individual, so that, in general, most selection procedures will select
individuals with lower kurtosis and skewness, since they are more
likely to draw a consistent value and thus go ahead to the next
generation. However, different selection procedures will affect them in different ways.  \textcolor{red}{This is why we have computed skewness and kurtosis for a sample of 20 from the 60 individuals of the population evaluated for 50 generations, and measured fitness values after the first, the 30th and the last generation for the three controllers;}
results are shown in Figure \ref{fig:gfcsk} (top, middle, bottom). 

%\begin{figure}[ht]	
%	\begin{center}
%          \includegraphics[width=8cm, height=2cm]{fig/GFC__.jpg}
%          \includegraphics[width=8cm, height=2cm]{fig/GFCRSE__.jpg}
%          \includegraphics[width=8cm, height=2cm]{fig/GFCVARSE__.jpg}
%		\caption{Skewness ($y$) and kurtosis ($x$)
%                  for the $f_{AVS}$ fitness in the  {\sf GFC} method \cite{salem_cig2018} (top), GPS score in {\sf GFC-GPSE} (middle) and {\sf GFC-GPSVAE} (bottom).}
%		\label{fig:gfcsk}
%	\end{center}	
%\end{figure}
\begin{figure}[ht]	
	\begin{center}
		\includegraphics[width=8cm, height=7cm]{fig/skew1.jpg}
		\caption{\textcolor{red}{Skewness ($y$) and kurtosis ($x$)
			for the $f_{AVS}$ fitness in the  {\sf GFC} method \cite{salem_cig2018} (top), GPS score in {\sf GFC-GPSE} (middle) and {\sf GFC-GPSVAE} (bottom).}}
		\label{fig:gfcsk}
	\end{center}	
\end{figure}
The figures show that the evolution process has a certain influence in
these measures, with individuals in the latest stages of evolution
getting their values closer to the origin, which would be a 0-skewness, 0-kurtosis
Gaussian. However, there are differences between the fitness-based
process ({\sf GFC}) and the other two, which are a fitnessless process. This is not only due to the fact that what we are measuring is a different value (fitness vs. selection score). 
In the first case, the
selection procedure simply eliminates the outliers with a high
skewness or kurtosis; there does not seem to be a big change from
generation 30 to 50, so as a matter of fact individuals with a high
and skewed variability are selected as {\em winners} when in fact they
are possibly not.

The two fitnessless methods, {\sf GFC-GPSE} and {\sf GFC-VA-GPSE}, are
notably similar, with selection eventually making the score of
individuals close to a Gaussian distribution, although slightly skewed
to the right, and with a positive fat tail. However, {\sf GFC-GPSVAE}
is able to find solutions with lower skewness, always between -0.5 and
1. Since this method exploits more found solutions, it seems that it
is able to generate new solutions with a more reliable expected value
around the middle of the area the variable covers, but decreasing more
slowly towards values away from the center. For the time being, we can
affirm that fitnessless methods tend to evolve individuals with a
score that is less uncertain, and thus more robust and whose expected
results are more reliable; this was an objective of this GPS
procedure, and we consider it has been achieved\textcolor{red}{, as it can be seen in
Figure \ref{fig:gfcsk}: this last method reaches the minimal
dispersion of skewness in the 50th generation, with kurtosis in a
distribution that is similar to {\sf GFC-GPSE}, but in either case
with a lower variability than the one found in the original {\sf GFC} algorithm}. Although we have
represented a single run here, results for other runs are similar.

In the next subsection we will see how this kind of selection has an influence in the success as a method for finding high-performance controllers.


% ---------------------------------------------------------------------------

\subsection{Testing Grand Prix Selection and BLX-$\alpha$ controllers}

Once the 10 runs have finished, the obtained best controllers from the
previous evolutionary processes compete again in a similar set of races, in order to choose the best controller overall per approach, i.e. the best between {\sf GFC-GPSL}, {\sf GFC-GPSE} and {\sf GFC-GPS5}; and also between {\sf GFC-GPSVAL}, {\sf GFC-GPSVAE} and {\sf GFC-GPSVA5}. The same F1 Grand Prix score used in GPS selection is considered. We run the selected controllers in 10 races of 20 laps for each of the two training tracks :Alpine 2  and Wheel 2  and  for each of the two testing tracks: E-Track 5 and Street 1. Results are shown in Table \ref{tab:GPS_and_Varyingalpha_RSresults}.
%% Process 1 : GPS without Alpha
%% Process 2  : GPS with Alpha
%%  GFC and VA are used only in comparaison purpose



\begin{table}[h!]
	\centering
	{\scriptsize
		\caption{ Results of GPS controllers  and varying $BLX-\alpha$ controllers in a mini-championship
			with 10 controllers and 10 races in two different training tracks and two testing tracks (20 laps each). {\tt tita}, {\tt berniw} and {\tt	inferno} are example controllers included with the TORCS
			simulator \cite{torcs4}. We mark in {\bf boldface}
                      the best value, and in {\em italics} the second best.}
		{
                  \begin{tabular}{|c|c|>{\columncolor[gray]{.9}}c|c|c||c|}
                  	              \hline
                  	\multicolumn{6}{|c|}{Results of GPS controllers} \\
                    \hline
                    
%                    \rowcolor{gray!30}
                    & \multicolumn{2}{|c|}{Training tracks} &\multicolumn{2}{|c|}{Testing tracks} \\
                    \hline
                    Controller&\textit{Alpine 2} &Wheel 2&\textit{E-Track 5}  &Street 1&Total\\
				\hline
				\hline
			
			{\sf GFC-GPSE}&216& 222& 236&222&{\bf 896}\\	
			{\sf GFC-GPS5}\cite{DBLP:conf/cig/SalemMG19}&170&162&176&180&{\em688}\\
			
			{\sf GFC-GPSL}\cite{DBLP:conf/cig/SalemMG19}&164&154&156&156&630\\
			{\sf GFC} \cite{salem_cig2018}	&140&116& 86&114&456\\
			{\sf GFC-VA}\cite{DBLP:conf/cig/SalemMG19}	&102&102& 68& 90&362\\



			$berniw2$	& 84&100&100& 72&356\\
			$tita1$	&44 & 64& 58& 60&226\\
			$inferno2$&50& 34& 72& 50&206\\				
			$berniw1$	& 24& 26& 42& 52&144\\			
			$inferno1$& 16& 30& 16& 14& 76\\			
			
				\hline
%
%				
%			\end{tabular}
%		}\label{tab:RSresults}
%	}
%\end{table}
%%
%\begin{table}[h!]
%	\centering
%	{\scriptsize
%          \caption{\textcolor{red}{ Results of adaptive $BLX-\alpha$ controllers in a mini-championship with 10 controllers
%          	and 10 races in two different training tracks and two testing tracks (20 laps each). {\tt tita}, {\tt berniw} and {\tt inferno} are example controllers included with the TORCS simulator \cite{torcs4}. {\bf Boldface} for the absolute winner, {\em italics} for the second best.}}
%          {
%            \begin{tabular}{|c|c|c|c|c||c|}
              \hline
               \multicolumn{6}{|c|}{Results of varying $BLX-\alpha$ controllers} \\
                            \hline
%                    & \multicolumn{2}{|c|}{Training tracks} &\multicolumn{2}{|c|}{Testing tracks} \\
              \hline
                    Controller&\textit{Alpine 2} &Wheel 2&\textit{E-Track 5}  &Street 1&Total\\
              \hline
              \hline	
              {\sf GFC-GPSVAE} &236&	236&250&236&{\bf 958}\\
              {\sf GFC-GPSVA5} \cite{DBLP:conf/cig/SalemMG19}&170&	188&162&188&	{\em 708}\\

				{\sf GFC-GPSVAL} \cite{DBLP:conf/cig/SalemMG19}&152&	156&146&	156&	610\\

				
				
		{\sf GFC-VA} \cite{DBLP:conf/cig/SalemMG19}&124&96 &102&	108&	430\\		
		{\sf GFC}  \cite{salem_cig2018}&102&	96 &88 &	100&	386\\
		$berniw2$	 &76 &	88 &74 &76 &	314\\
		$tita1$	 	&52 &60 &56 &	56 &	224\\
		$inferno2$ &40 &	44 &80 &	24 &	188\\		
		$berniw1$	 &36 &	24 &30 &	48 &	138\\	
		$inferno1$ &22 &	22 &18 &18 &	80\\					\hline			
			\end{tabular}
		}\label{tab:GPS_and_Varyingalpha_RSresults}
	}
\end{table}
%
As it could be noticed in Table \ref{tab:GPS_and_Varyingalpha_RSresults} (top subtable), the controller {\sf GFC-GPSE} has won the Grand Prix championship obtaining 438 points from 500 in the tracks used in the training, it has also ranked first in the testing tracks  \textit{E-Track 5} and \textit{Street 1}. 
The other GPS based controllers have obtained nearly the same results (149 and 158 respectively).
From the same subtable, it is clear that the controller {\sf GFC-GPSE}, where GPS selection has been applied in every generation, has won the majority of possible points in the four tracks, even in the unknown (not trained) \textit{E-Track 5}  and \textit{Street 1} tracks.

These results come to confirm the influence of the proposed selection policy where the controllers obtained from applying only the GPS selection have won the competition (comparing the points obtained by GPS controllers and GFC).
Indeed, we have made a `realistic' selection process by eliminating
the classical fitness function based on the speed and damage average
and replacing it by points obtained in direct races. 
Performance in solo racing can be an acceptable criterion for a good
controller, as proved so far, but at the end of the day, the best car
is the one that wins races. Thus, the new selection policy allows us
to select actual winners on the field and not controllers that perform
well in {\em training} races and could, thus, be potential winners.

% ----------------

The following experimentation is dedicated to assess the impact of the
$BLX-\alpha$ operator; the same process has been followed
selecting the best controllers of the evolution from those which
have used this varying-$\alpha$ crossover operator and testing them in several
races. Results are shown in Table \ref{tab:GPS_and_Varyingalpha_RSresults} (bottom subtable). 
%
%
%\begin{table}[ht]
%	\centering
%	{\scriptsize
%          \caption{\textcolor{red}{ Results of adaptive $BLX-\alpha$ controllers in a mini-championship with 10 controllers
%          	and 10 races in two different training tracks and two testing tracks (20 laps each). {\tt tita}, {\tt berniw} and {\tt inferno} are example controllers included with the TORCS simulator \cite{torcs4}. {\bf Boldface} for the absolute winner, {\em italics} for the second best.}}
%          {
%            \begin{tabular}{|c|c|c|c|c||c|}
%              \hline
%                    & \multicolumn{2}{|c|}{Training tracks} &\multicolumn{2}{|c|}{Testing tracks} \\
%              \hline
%                    Controller&\textit{Alpine 2} &Wheel 2&\textit{E-Track 5}  &Street 1&Total\\
%              \hline
%              \hline	
%              {\sf GFC-GPSVAE} &\cellcolor{red!25}236&\cellcolor{red!25}	236&\cellcolor{red!25}250&	\cellcolor{red!25}236&\cellcolor{red!25}{\bf 958}\\
%              {\sf GFC-GPSVA5} \cite{DBLP:conf/cig/SalemMG19}&\cellcolor{red!25}170&\cellcolor{red!25}	188&\cellcolor{red!25}162&	\cellcolor{red!25}188&\cellcolor{red!25}	{\em 708}\\
%
%				{\sf GFC-GPSVAL} \cite{DBLP:conf/cig/SalemMG19}&\cellcolor{red!25}152&	\cellcolor{red!25}156&\cellcolor{red!25}146&\cellcolor{red!25}	156&\cellcolor{red!25}	610\\
%
%				
%				
%		{\sf GFC-VA} \cite{DBLP:conf/cig/SalemMG19}&\cellcolor{red!25}124&\cellcolor{red!25}	96 &\cellcolor{red!25}102&\cellcolor{red!25}	108&\cellcolor{red!25}	430\\		
%		{\sf GFC}  \cite{salem_cig2018}&\cellcolor{red!25}102&\cellcolor{red!25}	96 &\cellcolor{red!25}88 &\cellcolor{red!25}	100&\cellcolor{red!25}	386\\
%		$berniw2$	 &\cellcolor{red!25}76 &\cellcolor{red!25}	88 &\cellcolor{red!25}74 &	\cellcolor{red!25}76 &\cellcolor{red!25}	314\\
%		$tita1$	 	&\cellcolor{red!25}52 &	\cellcolor{red!25}60 &\cellcolor{red!25}56 &\cellcolor{red!25}	56 &\cellcolor{red!25}	224\\
%		$inferno2$ &\cellcolor{red!25}40 &\cellcolor{red!25}	44 &\cellcolor{red!25}80 &	\cellcolor{red!25}24 &\cellcolor{red!25}	188\\		
%		$berniw1$	 &\cellcolor{red!25}36 &\cellcolor{red!25}	24 &\cellcolor{red!25}30 &	\cellcolor{red!25}48 &\cellcolor{red!25}	138\\	
%		$inferno1$ &\cellcolor{red!25}22 &\cellcolor{red!25}	22 &\cellcolor{red!25}18 &\cellcolor{red!25}	18 &\cellcolor{red!25}	80\\					\hline			
%			\end{tabular}
%		}\label{tab:VaryingalphaRSresults}
%	}
%\end{table}
%

As it can be seen in the table, again the controller using GPS in
every generation has reached the best score, but it should be noted the
big impact of the application of the varying $BLX-\alpha$ operator in
all the controllers. Thus, looking again at the results in Table \ref{tab:GPS_and_Varyingalpha_RSresults} (bottom subtable) 
% please add reference - JJ
% Antonio - done
and comparing them with those in the top subtable (results of GPS controllers), the increase in the obtained score is evident, at least in the first
two. % Probably putting those tables together would be better - JJ
% Antonio - I have put them consecutively in the page. Maybe if we need to save space we could fuse them in the same table with a common caption. But now I think we could let them like this.
% Antonio - Ok, now they are together in the same table. ;)
Thus, the introduction of the $BLX-\alpha$ operator allows the parameters of the controllers to be refined and increases diversification in the optimization process, which has led to better results.
Finally, the best controllers obtained from the two main optimization
processes: {\sf GFC-GPSVAE} and {\sf GFC-GPSE} are evaluated in a F1 like
mini-championship against the previous five TORCS bots and the {\sf GFC-VA}\cite{DBLP:conf/cig/SalemMG19} and {\sf GFC} controllers  \cite{salem_cig2018}. 



We have also considered a new rival from the state of the art, which participated in several Simulated Car Racing Competitions in past editions. 
It was proposed by P{\'e}rez-Li{\'e}bana, S{\'a}ez, Recio and Isasi
\cite{EvolvingRuleSystem08} and later refined in the work
\cite{PerezEvolvingFuzzy09}. We have baptized it as \textit{PSRI} in honor of
its authors' surnames. 
Table \ref{tab:allsresults} shows the obtained results.
%

\begin{table}[ht]
  \centering
  {\scriptsize
    \caption{ Results of {\sf GFC-GPSVAE} and {\sf GFC-GPSE}
      in a mini-championship with 10 controllers
      and 10 races in two different training tracks and two testing tracks (20 laps each). {\tt tita}, {\tt berniw} and {\tt inferno} are example controllers included with the TORCS
      simulator \cite{torcs4}.  {\bf Boldface} is used to highlight the best value, {\em italics} for the second best.}
    {
            \begin{tabular}{|c|c|c|c|c||c|}
	\hline
	& \multicolumn{2}{|c|}{Training tracks} &\multicolumn{2}{|c|}{Testing tracks} \\
	\hline
	Controller&\textit{Alpine 2} &Wheel 2&\textit{E-Track 5}  &Street 1&Total\\
        \hline
        \hline



{\sf GFC-GPSVAE}	&222&236&236&222&	{\bf 916}\\
{\sf GFC-GPSE}	&176&196&162&190&{\em 724}\\

{\sf GFC-VA} \cite{DBLP:conf/cig/SalemMG19}&172&146&	134&152& 604\\
{\sf GFC}  \cite{salem_cig2018}	&108&	120&110&	112&	450\\
$PSRI$\cite{PerezEvolvingFuzzy09}&102&88 &104&86 &380\\
$berniw2$		&88	&84 &92 &72 &336\\
$inferno2$	&58	&34 &80 &50 &222\\
$tita1$		&34 &64 &36 &60 &194\\
$berniw1$		&32	&26 &48 &52 &158\\
$inferno1$	&18	&30 &16 &14 &78\\
\hline

\end{tabular}
}\label{tab:allsresults}
}
\end{table}




This final competition shows {\sf GFC-GPSVAE} clearly leading. It collected most of the points in the four tracks, leaving the {\sf GFC-GPSE} controller far behind it. The reference drivers, namely {\sf GFC-VA} and {\sf GFC}  are classified $3^{rd}$ and $4^{th}$.

%%%%%%%%%%  controller GFC-VAGPSE MFs

As an additional results, we depict the structure of the winner controller {\sf GFC-GPSVAE} in Figure \ref{fig:frontmfs}. 
If we take into account the rules already set in Table
\ref{tab:output}, the shape of the obtained MFs  is in accordance with
what a human driver would have done: favor speed as much as possible
in the straight sections and brake as late as possible in the turns. 
According to the figures, we have more than three quarters of
probability that the first three rules will activate; these rules
would make the car very aggressive especially in the straight sections
of the track. The MFs for the FRONT sensor are for most of the values
either Medium or High, which means that the target speed output will
be over 240 km/h for the majority of the sensor range. 
That situation is similar for the MAX5 and MAX10 MFs: turning will be done smoothly, and only in a very extreme situation (with the FRONT sensor in LOW and
the other two sensors or medium or high, it will take a sharp turn;
considering the physics of the simulator, these sharp turns might lead
to getting off track and thus damage to the car.

%
\begin{figure}[h]	
  \begin{center}
    \includegraphics[width=8.5cm, height=1.9cm]{fig/FRONT.jpg}
    \includegraphics[width=8.5cm, height=1.9cm]{fig/MAX5.jpg}
    \includegraphics[width=8.5cm, height=1.9cm]{fig/MAX10.jpg}		
    \caption{FRONT, MAX5 and MAX10 input membership functions for a controller obtained with the {\sf GFC-GPSVAE} method.}
    \label{fig:frontmfs}
\end{center}	
\end{figure}
%\begin{figure}[!ht]	
%	\begin{center}
%		\includegraphics[width=9cm]{fig/MAX5.jpg}
%		\caption{MAX5 input membership for 
%			{\sf GFC-GPSVAE}.}
%		\label{fig:max5mfs}	
%	\end{center}	
%\end{figure}
%\begin{figure}[!ht]	
%	\begin{center}
%		\includegraphics[width=9cm]{fig/MAX10.jpg}
%		\caption{MAX10 input membership for 
%			{\sf GFC-GPSVAE}.}
%		\label{fig:max10mfs}	
%	\end{center}	
%\end{figure}
%
Since these MFs lead to a very reliable performance in the car, it
validates our approach of using fixed rules. It should
also be noted that the fact that we are using fuzzy controllers allows
us for an easy interpretation of the behavior of the car, something
that would not be possible if other black-box heuristics were used.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\textcolor{red}{
To evaluate the cost of the proposed controllers, we run the evolutionary optimization for 50 generations and 10 runs for all the considered controllers.
 Table \ref{tab:time} shows the average running time and  as additional information, the range of generations where the best individual was found. } 

\begin{table}[!ht]
	\centering
	{\scriptsize
          \caption{Average runtime in 10 runs of 10 races 
          	 %  Isn't this
                                %  average running time? - JJ
            and
                  generation where the best individual was spawned.}
		\label{tab:time}
		\begin{tabular}{|p{2.85cm}|p{2.20cm}|p{1.65cm}|}
			\hline  
			Controller& \textbf{Avg Runtime (s)}&\textbf{Generation}\\
% Is this number of laps or running time? - Jj
%Mohammed %% each lap in Alpine 2  takes between 90s and 120s
%% number of completed laps,  I prefered the laps number to high
%% values of average running time values ( 123800s for instance)
                  % But still all cars run the same amount of laps in
                  % every race. It probably makes sense to use time
                  % here - JJ
\hline
\hline 	 
 \textbf{{\sf GFC-GPSVAL}} \cite{DBLP:conf/cig/SalemMG19}&282923
&7-14\\	
\textbf{{\sf GFC-GPSVAE}}&287200
&11-16\\
 \textbf{{\sf GFC-GPSE}}&289850
&20-39\\
\textbf{{\sf GFC-VA}} \cite{DBLP:conf/cig/SalemMG19}&293000
&9-18\\
 \textbf{{\sf GFC-GPSL}} \cite{DBLP:conf/cig/SalemMG19}&295445
&21-35\\
\textbf{\textbf{{\sf GFC}}} \cite{salem_cig2018}&402000
                   &32-36\\
\textbf{{\sf GFC-GPSVA5}} \cite{DBLP:conf/cig/SalemMG19}&436520
&7-15\\		
 \textbf{{\sf GFC-GPS5}} \cite{DBLP:conf/cig/SalemMG19}&443860
				&21-35\\	
					
			\hline 
		
		\end{tabular}
		
	}
\end{table} 
\textcolor{red}{{\sf GFC-GPSVAE} and {\sf GFC-GPSE} controllers were the best where
they are ranked $1^{st}$ and $2^{nd}$ in the comparative competition (See Table \ref{tab:allsresults}) but they are very expensive in runtime}, since they have performed around 282923s and 287200s respectively, which is a
huge training time. % Don't all individuals use the same amount of
                    % laps to race? - JJ                    
                 % Mohammed : in fitnessless  case , time of a race is the time of the worst individual 
                 % Time of BLX based aproaches, ind are close to each other, so the difference between the best and the wort is less, this factor, decreases the whole runtime                 
This means that, even if the proposed selection policy is very effective, in turn, it requires a lot of computation time.
%
Another point that we can highlight is that the controllers with
$BLX-\alpha$ have reached the optimal solution in few generations
(between the $7^{th}$ and the $20^{th}$) while the other methods required more
generations. 
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and Future Work} 
\label{sec:conclusions}

% >>>>>> TODO: Rewrite this section -> All  <<<<<<<<<<
In this paper, and in order to avoid the impedance between using solo
racing scores and performance in competitive races, we have
incorporated this competition into the selection of individuals in an
evolutionary algorithm that evolves fuzzy controllers in the TORCS
simulator. This selection policy, called GPS (as in Grand Prix Selection), has been evaluated in combination with hybrid methods that use it only part of the time, and also together with an varying BLX-$\alpha$ and a standard crossover operators, to assess how it interacts with them and which combination yields the best competitive results.

% -------------------- this is reiterative and does not add anything -----
% We tried in a previous work to design a fitness which eliminates this uncertainty or reduces it by looking for the parameters which most affect the behavior of the controllers but the results obtained were not sufficiently satisfactory. In this paper, we started from a simple hypothesis: what if we let nature make the selection? Indeed, since the objective is to find the parameters of a winning controller, why not get rid of fitness and let nature do the rest.
% The main idea of this work is to overcome uncertainty by using a
% selection policy based on a system similar to Grand Prix championships
% where the score of a controller is the sum of the points collected
% during a set of races and in order to speed up the optimization
% process, we have introduced a new crossover operator: BLX-$\alpha$
% which improves exploration.
% ----------------------------------------------------------------

In races performed in the training, and other, tracks, the controller
that has evolved using competitive (fitnessless) selection and the
variable-$\alpha$ BLX crossover operator has proved superior to not
only other controllers evolved previously by us, but also other
competitive entries. As a matter of fact, the use of the GPS method has the greatest
influence in the results: {\sf GFC-GPSVAE} and {\sf GFC-GPSE}, whose only
difference lies in the kind of crossover operator they use, create the
best controllers, finishing first and second in competitive races and,
in the first case, obtain twice the score of a non-evolved
competitor such as $berniw2$.

The  BLX operator with decreasing $\alpha$ also has got a positive
influence in the outcome, outperforming the standard crossover
results. Thus, the decreasing amount of exploration that this BLX-$\alpha$ boasts seems to get to areas with better solutions in a
more efficient way, eventually finding very competitive controllers.

Another advantage of these combined selection and crossover operators is that they do not
increase too much the total training time, and are also able to find a
good solution in the first stages of evolution, which, if needed,
allows to cut the training short. {\sf GFC-GPSVAE} needs at most 18
generations (which is around one third of the maximum number of
generations defined) to find a good solution. Running GPS every
generation needs more generations to get to the best that if it is run
every 5 generations, or just at the end, but the problem is that in
those cases the solution found is less competitive. However, {\sf
  GFC-GPSVA5} is quite competitive, and in the case of a limited
evaluation budget, it could be a very good compromise.

As a conclusion, in this paper we have proved that combining a
fitnessless evolutionary algorithm with an varying, floating point,
crossover operator, consistently obtains the best results so far in
TORCS. The sets of choices of running track, car, controller and
actually parts of it that are evolving are thus also validated by
these results. Since the tracks have been specially selected to be as
general as possible, we think that this result could be extended to
other tracks, as long as ``training'' or evolution uses a track that
has as many different features as possible.

We also think that results are probably independent of the fact that we are using a set of fuzzy controllers. The results could be generalized to any kind
of controller, as long as the evolution process has the possibility to explore the space of controllers in the same, efficient, way. This is a possible
way of extending the work: substituting fuzzy controllers by simple
neural nets could be a way of proving that the fitnessless approach
is able to find good results independently of the low-level algorithms
using to drive the car. Fuzzy and neural controllers could be also
mixed, even coevolved, to try and find the best ones.

Additionally, we have been using heuristic rules for computing outputs
from the fuzzy rule activation. We could, however, consider optimizing
the outputs of the fuzzy controllers, as well as the rules.

The implementation could also be optimized. Right now, training takes
a long time. This optimization could go from parallelization, to basic
program-level improvement. All this is left as future work.

\section*{Acknowledgments}

This work has been supported in part by: Ministerio espa\~{n}ol de
Econom\'{\i}a y Competitividad under projects  TIN2017-85727-C4-2-P (UGR-DeepBio), as well as project RTI2018-102002-A-I00 (Ministerio espa\~{n}ol de Ciencia, Innovaci\'{\o}n y Universidades) and project B-TIC-402-UGR18 (FEDER and Junta de Andaluc\'{i}a).

\bibliographystyle{IEEEtranS}
\bibliography{fuzzy_torcs,geneura,uncertainty,fitnessless}


% Antonio - This should be included once it is accepted
%\begin{IEEEbiographynophoto}{Juan~J.~Merelo}
%Biography text here.
%\end{IEEEbiographynophoto}


% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}
